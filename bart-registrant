#!/usr/bin/env python

"""
Script to register usage records to SGAS ur servers.
Intented to be run from cron regularly (every hour or so)

This file is a bit messy, as it contains many things that would normally be
in seperate modules, but is contained in this single file in order to make
deployment easy (no imports, problems setting up PYTHONPATH, etc).

Authors: Henrik Thostrup Jensen <htj@ndgf.org>,
         Erik Edelmann <edelmann@csc.fi>
Copyright: Nordic Data Grid Facility (2009, 2010),
           Nordic e-Infrastructure Collaboration (2020)
"""

import sys
import os
import time

try:
    from urlparse import urlparse
except ImportError:
    from urllib.parse import urlparse

try:
    import ConfigParser
except ImportError:
    import configparser as ConfigParser

from bart import config
from bart.config import BartConfig

try:
    from xml.etree import cElementTree as ET
except ImportError:
    # Python 2.4 compatability
    from elementtree import ElementTree as ET

from OpenSSL import SSL
import logging

from twisted.internet import reactor, defer
from twisted.python import usage, failure
from twisted.web import client, http

from bart.usagerecord import urelements as ur

from bart.usagerecord import verify

# Nasty global so we can do proper exit codes
ERROR = False

# subdirectories in the spool directory

UR_DIRECTORY = 'urs'
STATE_DIRECTORY = 'state'
ARCHIVE_DIRECTORY = 'archive'

# -- code


class CommandLineOptions(usage.Options):

    optFlags = [ ['stdout', 's', 'Log to stdout'] ]
    optParameters = [
        ['config-file', 'c', config.DEFAULT_CONFIG_FILE, 'Config file to use (typically /etc/bart/bart.conf)'],
        ['log-file', 'l', config.DEFAULT_REGISTRANT_LOG_FILENAME, 'Log file' ]
    ]

class StateFile:
    """
    Abstraction for a ur statefile (describes whereto a UR
    has been registered).
    """
    def __init__(self, logdir, filename):
        self.logdir = logdir
        self.filename = filename

        statefile = self._filepath()
        if os.path.exists(statefile):
            self.urls = set([ line.strip() for line in open(statefile).readlines() if line.strip() ])
        else:
            statedir = os.path.join(logdir, STATE_DIRECTORY)
            if not os.path.exists(statedir):
                os.makedirs(statedir)
            self.urls = set()


    def _filepath(self):
        return os.path.join(self.logdir, STATE_DIRECTORY, self.filename)


    def __contains__(self, ele):
        return ele in self.urls


    def add(self, ele):
        if not ele in self.urls:
            self.urls.add(ele)
        return self # makes it possible to do one-liners


    def write(self):
        f = open(self._filepath(), 'w')
        for url in self.urls:
            f.write(url + "\n")
        f.close()



class ConfigurationError(Exception):
    pass



class ContextFactory:
    """
    SSL context factory. Which hostkey and cert files to use,
    and which CA to load, etc.
    """
    # Nicked from acix (but I wrote that anyway)

    def __init__(self, key_path, cert_path, ca_dir=None, verify=True):

        self.key_path = key_path
        self.cert_path = cert_path
        self.verify = verify
        self.ca_dir = ca_dir

        if self.verify and ca_dir is None:
            raise ConfigurationError('Certificate directory must be specified')


    def getContext(self):
        # should probably implement caching sometime

        ctx = SSL.Context(SSL.SSLv23_METHOD) # this also allows tls 1.0
        ctx.set_options(SSL.OP_NO_SSLv2) # ssl2 is unsafe

        ctx.use_privatekey_file(self.key_path)
        ctx.use_certificate_file(self.cert_path)
        ctx.check_privatekey() # sanity check

        def verify_callback(conn, x509, error_number, error_depth, allowed):
            # just return what openssl thinks is right
            return allowed

        if self.verify:
            ctx.set_verify(SSL.VERIFY_PEER, verify_callback)

            calist = [ ca for ca in os.listdir(self.ca_dir) if ca.endswith('.0') ]
            for ca in calist:
                # openssl wants absolute paths
                ca = os.path.join(self.ca_dir, ca)
                ctx.load_verify_locations(ca)

        return ctx


def getConfigOption(cfg, section, option, default=None):

    clean = lambda s : type(s) == str and s.strip().replace('"','').replace("'",'') or s

    try:
        value = cfg.get(section, option)
        return clean(value)
    except ConfigParser.NoSectionError:
        pass
    except ConfigParser.NoOptionError:
        pass

    return default


def parseLogAll(value):
    return value.split(' ') if value else None


def parseLogVO(value):
    vo_regs = {}

    if value == None or len(value) == 0:
        return vo_regs

    pairs = value.split(',')
    for pair in pairs:
        vo_name, url = pair.strip().split(' ',2) 
        vo_regs[vo_name] = url
    return vo_regs


def parseURLifeTime(value):
    ur_lifetime_days = int(value)
    ur_lifetime_seconds = ur_lifetime_days * (24 * 60 * 60)
    return ur_lifetime_seconds


def getVONamesFromUsageRecord(ure):
    """
    Return the VO name element values of a usage record.
    """
    # for some reason the followng fails :-/
    # >>> ur.getroot().findall(VO_NAME)
    # so we do it the silly way and iterate over the tree instead.

    vos = []
    for e in ure.getroot():
        if e.tag == ur.USER_IDENTITY:
            for f in e:
                if f.tag == ur.VO:
                    for g in f:
                        if g.tag == ur.VO_NAME:
                            vos.append(g.text)
    return vos




def createRegistrationPointsMapping(logdir, logpoints_all, logpoints_vo):
    """
    Create a mapping from all the usage records filenames to which endpoints they
    should be registered.
    """
    logging.info("Creating registration mapping (may take a little time)")
    mapping = {}

    ur_dir = os.path.join(logdir, UR_DIRECTORY)
    for filename in os.listdir(ur_dir):
        filepath = os.path.join(ur_dir, filename)
        # skip if file is not a proper file
        if not os.path.isfile(filepath):
            continue

        try:
            ure = ET.parse(filepath)
        except Exception:
            logging.error('Error parsing file %(filepath)s, continuing' % {'filepath' : filepath})
            continue
        
        if verify.verify(ure.getroot()) is False:
            logging.error('Error verifing file %(filepath)s, continuing' % {'filepath' : filepath})
            continue

        vos = getVONamesFromUsageRecord(ure)

        for lp in logpoints_all:
            mapping.setdefault(lp, []).append(filename)
        for vo in vos:
            vo_lp = logpoints_vo.get(vo)
            if vo_lp:
                mapping.setdefault(vo_lp, []).append(filename)

    return mapping



def createFileEPMapping(epmap):
    # creates filename -> [endpoint] map
    # makes it easy to know when all registrations have been made for a file
    fnepmap = {}
    for ep, filenames in epmap.items():
        for fn in filenames:
            fnepmap.setdefault(fn, []).append(ep)
    return fnepmap



def httpRequest(url, method=b'GET', payload=None, ctxFactory=None):
    # probably need a header options as well
    """
    Peform a http request.
    """
    # copied from twisted.web.client in order to get access to the
    # factory (which contains response codes, headers, etc)

    scheme, netloc, path, params, query, fragment = urlparse(url.encode(encoding='utf-8'))

    if scheme == b'https':
        defaultPort = 443
    else:
        defaultPort = 80

    host, port = netloc, defaultPort
    if b':' in host:
        host, port = host.split(b':')
        try:
            port = int(port)
        except ValueError:
            port = defaultPort
    
    factory = client.HTTPClientFactory(url.encode(encoding='utf-8'), method=method, postdata=payload)
    factory.noisy = False # stop spewing about factory start/stop
    # fix missing port in header (bug in twisted.web.client)
    if port:
        factory.headers[b'host'] = host.decode(encoding='utf-8') + ':' + str(port)

    if scheme == b'https':
        reactor.connectSSL(host.decode(encoding='utf-8'), port, factory, ctxFactory)
    else:
        reactor.connectTCP(host.decode(encoding='utf-8'), port, factory)

    return factory.deferred, factory



def createEPRegistrationMapping(endpoints, ctxFactory):

    def createRegistrationURL(location, endpoint):
        if location.startswith('http'):
            # location is a complete url, so we just return it
            return location
        elif location.startswith('/'):
            # location is a path, and must be merged with base endpoint to form a suitable url
            url = urlparse(endpoint)
            reg_url = url[0] + '://' + url[1] + location
            return reg_url
        else:
            raise ValueError('Invalid registration point returned by %s (got: %s)' % (endpoint, location))


    def gotReply(result, factory, endpoint):

        tree = ET.fromstring(result)
        for service in tree:
            if service.tag == 'service':
                found_service = False
                for ele in service:
                    if ele.tag == 'name' and ele.text == 'Registration':
                        found_service = True
                    elif ele.tag == 'href' and found_service == True:
                        location = ele.text
                        return createRegistrationURL(location, endpoint)
        return None # no registration service found

    def mergeResults(results, endpoints):
        regmap = {}
        for (success, result), ep in zip(results, endpoints):
            if success and result is not None:
                regmap[ep] = result
            elif success:
                logging.error('Endpoint %s does not appear to have a registration service.' % ep)
            else:
                logging.error('Error contacting service %s (%s)' % (ep, result.getErrorMessage()))
        return regmap

    defs = []
    for ep in endpoints:
        d, f = httpRequest(ep, ctxFactory=ctxFactory)
        d.addCallback(gotReply, f, ep)
        defs.append(d)

    dl = defer.DeferredList(defs, consumeErrors=1) # otherwise we'll get complaints
    dl.addCallback(mergeResults, endpoints)
    return dl



def insertUsageRecords(url, payload, ctxFactory):
    """
    Upload (insert) one or more usage record in a usage record
    service.
    """
    def gotResponse(result, factory, url):
        if factory.status != b'200':
            logging.error("Reply from %s had other response code than 200 (%s)" % (url, factory.status))
        return result

    d, f = httpRequest(url, method=b'POST', payload=payload, ctxFactory=ctxFactory)
    d.addCallback(gotResponse, f, url)
    return d



def joinUsageRecordFiles(logdir, filenames):

    urs = ET.Element(ur.USAGE_RECORDS)

    for fn in filenames:
        filepath = os.path.join(logdir, UR_DIRECTORY, fn)
        if os.path.getsize(filepath) == 0:
            logging.info("Skipping file %s for transmit as it is empty" % fn)
            continue
        ure = ET.parse(filepath)
        urs.append(ure.getroot())

    return ET.tostring(urs)



def registerBatch(ep, url, logdir, filenames, ctxFactory):

    def insertDone(result):
        logging.info("%i records registered to %s" % (len(filenames), ep))
        for fn in filenames:
            StateFile(logdir, fn).add(ep).write()

    def insertError(error):
        logging.error("Error during batch insertion: %s" % error.getErrorMessage())
        return error

    ur_data = joinUsageRecordFiles(logdir, filenames)

    d = insertUsageRecords(url, ur_data, ctxFactory)
    d.addCallbacks(insertDone, insertError)
    return d



def registerUsageRecords(mapping, logdir, ctxFactory, batch_size=config.DEFAULT_BATCH_SIZE):
    """
    Register usage records, given a mapping of where to
    register the usage records.
    """
    urmap = createFileEPMapping(mapping)
    if not urmap: # no registration to perform
        logging.info("No registrations to perform")
        return defer.succeed(None)

    logging.info("Registrations to perform: %i files" % len(urmap))
    logging.info("Retrieving registration hrefs (service endpoints)")
    d = createEPRegistrationMapping(mapping.keys(), ctxFactory)

    d.addCallback(_performURRegistration, urmap, logdir, ctxFactory, batch_size)
    archive = lambda _, logdir, urmap : archiveUsageRecords(logdir, urmap)
    d.addCallback(archive, logdir, urmap)
    return d



def _performURRegistration(regmap, urmap, logdir, ctxFactory, batch_size):

    if not regmap:
        logging.error("Failed to get any service refs, not doing any registrations")
        return defer.fail(Exception("Failed to get any service refs, not doing any registrations"))

    batch_sets = {}
    for ep, urreg in regmap.items():
        logging.info("%s -> %s" % (ep, urreg))
        batch_sets[ep] = []

    logging.info("Starting registration")

    skipped_registrations = {}

    # new registration logic (batching)
    for filename, endpoints in urmap.items():

        state = StateFile(logdir, filename)
        for ep in endpoints:
            if ep in state:
                skipped_registrations[ep] = skipped_registrations.get(ep, 0) + 1
                continue
            try:
                batch_sets[ep].append(filename)
            except KeyError:
                pass # deferring registration as service is not available

    for ep, ur_registered in skipped_registrations.items():
        logging.info("Skipping %i registrations to %s, records already registered" % (ur_registered, ep))

    # build up registraion batches (list of (ep, filenames) tuples)
    registrations = []
    for ep, filenames in batch_sets.items():
        registrations += [ (ep, filenames[i:i+batch_size]) for i in range(0, len(filenames), batch_size) ]

    registration_deferred = defer.Deferred()

    error_endpoints = {}

    def doBatch(result, used_service_endpoint):
        if isinstance(result, failure.Failure):
            # something went wrong in the registration - stop future registrations
            # split into to 2 lines (far easier to read in the log)
            logging.error("Error registration records to %s (%s)" % (used_service_endpoint,result.getErrorMessage()))
            logging.info("Skipping all registrations to this endpoint for now")
            error_endpoints[used_service_endpoint] = True

        try:
            service_endpoint, filenames = registrations.pop(0)
            while service_endpoint in error_endpoints:
                service_endpoint, filenames = registrations.pop(0)

            d = registerBatch(service_endpoint, regmap[service_endpoint], logdir, filenames, ctxFactory)
            d.addBoth(doBatch, service_endpoint)
        except IndexError:
            # no more registrations
            registration_deferred.callback(None)

    doBatch(None, None)

    return registration_deferred


def archiveUsageRecords(logdir, urmap):

    logging.info("Registration done, commencing archiving process")
    archive_dir = os.path.join(logdir, ARCHIVE_DIRECTORY)
    if not os.path.exists(archive_dir):
        os.makedirs(archive_dir)

    for filename, endpoints in urmap.items():
        state = StateFile(logdir, filename)
        for ep in endpoints:
            if not ep in state:
                break
        else:
            urfilepath = os.path.join(logdir, UR_DIRECTORY, filename)
            statefilepath = os.path.join(logdir, STATE_DIRECTORY, filename)
            archivefilepath = os.path.join(logdir, ARCHIVE_DIRECTORY, filename)
            os.unlink(statefilepath)
            os.rename(urfilepath, archivefilepath)

    logging.info("Archiving done")



def deleteOldUsageRecords(log_dir, ttl_seconds):

    archive_dir = os.path.join(log_dir, ARCHIVE_DIRECTORY)
    logging.info("Cleaning up old records.")

    now = time.time()

    i = 0
    for filename in os.listdir(archive_dir):
        filepath = os.path.join(archive_dir, filename)
        # skip if file is not a proper file
        if not os.path.isfile(filepath):
            continue

        # use ctime to determine file age
        f_ctime = os.stat(filepath).st_ctime

        if f_ctime + ttl_seconds < now:
            # file is old, will get deleted
            os.unlink(filepath)
            i += 1

    logging.info("Records deleted: %i" % i)
    return defer.succeed(None)


def LogStderrObserver(msg, stderr_level):
    if not stderr_level:
        return

    # Check whether to write the message to stderr.
    #
    # If we wanted to be fancy, we could also take msg['logLevel'] into
    # account (if provided), but I'm too lazy
    if(stderr_level in ('ERROR', 'CRITICAL') and msg['isError']) or stderr_level in ('DEBUG', 'INFO', 'WARNING'):
        sys.stderr.write("%s\n" % msg['message'])


def doMain():
    """
    "Real" main, parse command line, setup logging, start the actual logic, etc.
    """
    # start by parsing the command line to see if we have a specific config file
    cmd_cfg = CommandLineOptions()
    try:
        cmd_cfg.parseOptions()
    except SystemExit as e:
        return # deal with silly sys.exit(0) in twisted.python.usage
    except usage.UsageError as e:
        print('%s: %s' % (sys.argv[0], str(e)))
        print('%s: Try --help for usage details.' % (sys.argv[0]))
        return

    cfg_file = cmd_cfg['config-file']
    try:
        cfg = BartConfig(cfg_file)
    except Exception as e:
        sys.stderr.write("Can't read config file: %s\n" % e)
        sys.exit(1)

    # Log level
    #if options.debug:
    #    loglevel = logging.DEBUG
    #else:
    loglevel = cfg.getLoglevel()

    if cmd_cfg['stdout']:
        logging.basicConfig(stream=sys.stdout, format=config.LOG_FORMAT, level=loglevel)
    else:
        logging.basicConfig(filename=cmd_cfg['log-file'], format=config.LOG_FORMAT, level=loglevel)

    stderr_level = cfg.getConfigValue(config.SECTION_COMMON, config.STDERR_LEVEL, config.DEFAULT_STDERR_LEVEL)
    if stderr_level:
        stderr_handler = logging.StreamHandler()
        stderr_handler.setLevel(stderr_level)
        logging.getLogger().addHandler(stderr_handler)


    log_dir = cfg.getConfigValue(config.SECTION_COMMON, config.LOGDIR, config.DEFAULT_LOG_DIR)

    las = cfg.getConfigValue(config.SECTION_LOGGER, config.LOG_ALL)
    lvo = cfg.getConfigValue(config.SECTION_LOGGER, config.LOG_VO)
    ult = cfg.getConfigValue(config.SECTION_LOGGER, config.UR_LIFETIME, config.DEFAULT_UR_LIFETIME)
    log_all = parseLogAll(las)
    log_vo  = parseLogVO(lvo)
    ur_lifetime = parseURLifeTime(ult)

    host_key  = cfg.getConfigValue(config.SECTION_COMMON, config.HOSTKEY, config.DEFAULT_HOSTKEY)
    host_cert = cfg.getConfigValue(config.SECTION_COMMON, config.HOSTCERT, config.DEFAULT_HOSTCERT)
    cert_dir  = cfg.getConfigValue(config.SECTION_COMMON, config.CERTDIR, config.DEFAULT_CERTDIR)

    logging.info('Configuration:')
    logging.info(' Log dir: %s' % log_dir)
    logging.info(' Log all: %s' % log_all)
    logging.info(' Log vo : %s' % log_vo)

    if not (log_all or log_vo):
        logging.error('No log points given. Cowardly refusing to do anything')
        return

    if not os.path.exists(log_dir):
        logging.error('Log directory %s does not exist, bailing out.' % log_dir)
        return

    mapping = createRegistrationPointsMapping(log_dir, log_all, log_vo)
    cf = ContextFactory(host_key, host_cert, cert_dir)
    d = registerUsageRecords(mapping, log_dir, cf)
    d.addCallback(lambda _ : deleteOldUsageRecords(log_dir, ur_lifetime))
    return d



def main():
    """
    main, mainly a wrapper over the rest of the program.
    """
    def handleError(error):
        global ERROR
        ERROR = True
        if error.type == SystemExit:
            logging.error('SystemExit: %s' % error.value)
        else:
            error.printTraceback()

    d = defer.maybeDeferred(doMain)
    d.addErrback(handleError)
    d.addBoth(lambda _ : reactor.stop())
    return d



if __name__ == '__main__':
    reactor.callWhenRunning(main)
    reactor.run()

    if ERROR:
        sys.exit(1)

